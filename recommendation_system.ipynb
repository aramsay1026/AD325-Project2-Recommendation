{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f2dac1",
   "metadata": {},
   "source": [
    "# Recommendation System Project \n",
    "AD315 - Project 2\n",
    "Amy Ramsay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10ba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user6', 'Ghost of Tsushima']\n",
      "['user4', 'Fallout']\n",
      "['user6', 'Bloodborne']\n",
      "['user1', 'League of Legends']\n",
      "['user5', 'Super Mario Bros']\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import time \n",
    "from typing import List, Any, Optional \n",
    "\n",
    "# Preview the content of the CSV\n",
    "# This is 0(5) but if we were reading the whole file it would be 0(n) where n is number of rows\n",
    "def preview_csv(path=\"user_item_data.csv\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # skip header\n",
    "        for i in range(5):\n",
    "            print(next(reader))\n",
    "\n",
    "preview_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC user1: ['apple', 'banana']\n",
      "SC user2: ['carrot']\n",
      "SC collisions: 0\n",
      "SC table: [[], [], [], [['user1', ['apple', 'banana']]], [], [], [], [['user2', ['carrot']]], [], []]\n",
      "DH user1: ['apple', 'banana']\n",
      "DH user2: ['carrot']\n",
      "DH user3: ['donut']\n",
      "DH collisions: 1\n",
      "DH table: [None, None, None, ('user2', ['carrot']), None, None, ('user3', ['donut']), None, None, None, ('user1', ['apple', 'banana'])]\n"
     ]
    }
   ],
   "source": [
    "## HashTable (Base Class)\n",
    "from typing import Any\n",
    "\n",
    "class HashTable:\n",
    "    def __init__(self, size:int, collision_avoidance: str = \"separate_chaining\"):\n",
    "        self.size = size\n",
    "        self.collision_avoidance = collision_avoidance\n",
    "\n",
    "        # For separate chaining each slot is a list (bucket) of [key, items_list]\n",
    "        if collision_avoidance == \"separate_chaining\":\n",
    "            self.table = [[] for _ in range(size)]\n",
    "        else: \n",
    "            # Double hashing: flat array or entries \n",
    "            self.table = [None] * size \n",
    "\n",
    "        # Stats\n",
    "        self.collisions = 0\n",
    "\n",
    "    def hash(self, key: Any) -> int:\n",
    "        return hash(key) % self.size\n",
    "    \n",
    "    def second_hash(self, key: Any) -> int:\n",
    "        # For double hashing step size \n",
    "        return 1 + (hash(key) % (self.size - 1))\n",
    "    \n",
    "    def insert(self, key: Any, item: Any):\n",
    "        # Insert a (user, item) pair\n",
    "        # key: user ID (e.g., \"user42\")\n",
    "        # item: single item (e.g., \"item23\")\n",
    "\n",
    "        # Separate chaining\n",
    "        # Big O(1) average case \n",
    "        if self.collision_avoidance == \"separate_chaining\":\n",
    "            index = self.hash(key)\n",
    "            bucket = self.table[index]\n",
    "\n",
    "            # Look for existing key in bucket \n",
    "            for pair in bucket:\n",
    "                if pair[0] == key:\n",
    "                    items_list = pair[1]\n",
    "                    if item not in items_list:\n",
    "                        items_list.append(item)\n",
    "                    return\n",
    "                \n",
    "            # Key not found, create new entry\n",
    "            if bucket: \n",
    "                self.collisions += 1\n",
    "            bucket.append([key, [item]])\n",
    "            return\n",
    "        \n",
    "        # Double hashing\n",
    "        # Big O(1) average case \n",
    "        if self.collision_avoidance == \"double_hashing\":\n",
    "            index = self.hash(key)\n",
    "            step = self.second_hash(key)\n",
    "\n",
    "            original_index = index\n",
    "            i = 0\n",
    "\n",
    "            while True:\n",
    "                entry = self.table[index]\n",
    "\n",
    "                # Empty slow --> create new entry\n",
    "                if entry is None:\n",
    "                    self.table[index] = (key, [item])\n",
    "                    return \n",
    "                \n",
    "                # Same key --> append item if new \n",
    "                if entry[0] == key:\n",
    "                    items_list = entry[1]\n",
    "                    if item not in items_list:\n",
    "                        items_list.append(item)\n",
    "                        self.table[index] = (key, items_list)\n",
    "                    return\n",
    "                \n",
    "                # Collision --> probe to next index\n",
    "                self.collisions += 1\n",
    "                i += 1\n",
    "                index = (original_index + i * step) % self.size\n",
    "\n",
    "                if i >= self.size:\n",
    "                    raise Exception(\"Hash table is full\")\n",
    "\n",
    "\n",
    "    def retrieve(self, key: Any):\n",
    "        # Retrieve items list for given user key\n",
    "        # Big O(1) average case \n",
    "        if self.collision_avoidance == \"separate_chaining\":\n",
    "            index = self.hash(key)\n",
    "            bucket = self.table[index]\n",
    "\n",
    "            for pair in bucket:\n",
    "                if pair[0] == key:\n",
    "                    return pair[1]\n",
    "            return None\n",
    "        \n",
    "        # Big O(1) average case \n",
    "        if self.collision_avoidance == \"double_hashing\":\n",
    "            index = self.hash(key)\n",
    "            step = self.second_hash(key)\n",
    "\n",
    "            original_index = index\n",
    "            i = 0\n",
    "\n",
    "            while True:\n",
    "                entry = self.table[index]\n",
    "\n",
    "                if entry is None:\n",
    "                    return None # key not found\n",
    "                \n",
    "                if entry[0] == key:\n",
    "                    return entry[1]\n",
    "                \n",
    "                i += 1\n",
    "                index = (original_index + i * step) % self.size\n",
    "\n",
    "                if i >= self.size:\n",
    "                    return None\n",
    "                \n",
    "\n",
    "ht_chain = HashTable(10, collision_avoidance=\"separate_chaining\")\n",
    "ht_chain.insert(\"user1\", \"apple\")\n",
    "ht_chain.insert(\"user1\", \"banana\")\n",
    "ht_chain.insert(\"user2\", \"carrot\")\n",
    "\n",
    "print(\"SC user1:\", ht_chain.retrieve(\"user1\"))\n",
    "print(\"SC user2:\", ht_chain.retrieve(\"user2\"))\n",
    "print(\"SC collisions:\", ht_chain.collisions)\n",
    "print(\"SC table:\", ht_chain.table)\n",
    "\n",
    "ht_double = HashTable(11, collision_avoidance=\"double_hashing\")\n",
    "ht_double.insert(\"user1\", \"apple\")\n",
    "ht_double.insert(\"user1\", \"banana\")\n",
    "ht_double.insert(\"user2\", \"carrot\")\n",
    "ht_double.insert(\"user3\", \"donut\")\n",
    "\n",
    "print(\"DH user1:\", ht_double.retrieve(\"user1\"))\n",
    "print(\"DH user2:\", ht_double.retrieve(\"user2\"))\n",
    "print(\"DH user3:\", ht_double.retrieve(\"user3\"))\n",
    "print(\"DH collisions:\", ht_double.collisions)\n",
    "print(\"DH table:\", ht_double.table)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cace840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heap internal array: [(0.9, 'itemB'), (0.5, 'itemA'), (0.7, 'itemC'), (0.2, 'itemD')]\n",
      "Top 2: [(0.9, 'itemB'), (0.7, 'itemC')]\n",
      "Pop: (0.9, 'itemB')\n",
      "Pop: (0.7, 'itemC')\n",
      "Remaining heap: [(0.5, 'itemA'), (0.2, 'itemD')]\n"
     ]
    }
   ],
   "source": [
    "## MaxHeap\n",
    "\n",
    "class MaxHeap:\n",
    "    def __init__(self):\n",
    "        # store (priority, item) tuples\n",
    "        self.data = []\n",
    "    \n",
    "    def parent(self, index): \n",
    "        return (index - 1) // 2\n",
    "    \n",
    "    def left_child(self, index): \n",
    "        return 2 * index + 1\n",
    "    \n",
    "    def right_child(self, index): \n",
    "        return 2 * index + 2\n",
    "    \n",
    "    def has_left(self, index): \n",
    "        return self.left_child(index) < len(self.data)\n",
    "    \n",
    "    def has_right(self, index): \n",
    "        return self.right_child(index) < len(self.data)\n",
    "    \n",
    "    def swap(self, i, j):\n",
    "        self.data[i], self.data[j] = self.data[j], self.data[i]\n",
    "    \n",
    "    # O(log n) runtime - worst case number of swaps is height of tree \n",
    "    def percolate_up(self, index):\n",
    "        while index > 0:\n",
    "            parent_index = self.parent(index)\n",
    "            if self.data[index][0] > self.data[parent_index][0]:\n",
    "                self.swap(index, parent_index)\n",
    "                index = parent_index\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    # O(log n) runtime - worst case number of swaps is height of tree\n",
    "    def percolate_down(self, index):\n",
    "        while self.has_left(index):\n",
    "            largest_child_index = self.left_child(index)\n",
    "            if (self.has_right(index) and \n",
    "                self.data[self.right_child(index)][0] > self.data[largest_child_index][0]):\n",
    "                largest_child_index = self.right_child(index)\n",
    "            \n",
    "            if self.data[index][0] < self.data[largest_child_index][0]:\n",
    "                self.swap(index, largest_child_index)\n",
    "                index = largest_child_index\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def push(self, priority, item):\n",
    "        self.data.append((priority, item))\n",
    "        self.percolate_up(len(self.data) - 1)\n",
    "    \n",
    "    def pop(self):\n",
    "        if not self.data:\n",
    "            return None\n",
    "        self.swap(0, len(self.data) - 1)\n",
    "        item = self.data.pop()\n",
    "        self.percolate_down(0)\n",
    "        return item\n",
    "    \n",
    "    # Copying the heap is O(n)\n",
    "    # Popping n items is O(n log n)\n",
    "    def top_n(self, n):\n",
    "        result = []\n",
    "        temp_heap = MaxHeap()\n",
    "        temp_heap.data = self.data.copy()\n",
    "        \n",
    "        for _ in range(min(n, len(self.data))):\n",
    "            result.append(temp_heap.pop())\n",
    "        \n",
    "        return result\n",
    "    \n",
    "# Test MaxHeap implementation\n",
    "heap = MaxHeap()\n",
    "\n",
    "heap.push(0.5, \"itemA\")\n",
    "heap.push(0.9, \"itemB\")\n",
    "heap.push(0.7, \"itemC\")\n",
    "heap.push(0.2, \"itemD\")\n",
    "\n",
    "print(\"Heap internal array:\", heap.data)\n",
    "print(\"Top 2:\", heap.top_n(2))\n",
    "\n",
    "print(\"Pop:\", heap.pop())\n",
    "print(\"Pop:\", heap.pop())\n",
    "print(\"Remaining heap:\", heap.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9184d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 7\n",
      "First few users: ['user6', 'user4', 'user1', 'user5', 'user2']\n",
      "HashTable size (SC): 14\n",
      "SC collisions: 1\n",
      "Example user: user6\n",
      "Items for example user: {'Gears of War', 'Far Cry', 'League of Legends', 'Battlefield', 'Bayonetta', 'Bloodborne', 'The Last of Us', 'Super Mario Bros', 'Sekiro', \"Assassin's Creed\", 'Ghost of Tsushima', 'Horizon Zero Dawn'}\n",
      "Recommendations for user6 (SC): ['Red Dead Redemption 2', 'Dragon Age', 'Metal Gear Solid', 'World of Warcraft', 'The Legend of Zelda']\n",
      "HashTable size (DH): 14\n",
      "DH collisions: 10\n",
      "Recommendations for user6 (DH): ['Red Dead Redemption 2', 'Dragon Age', 'Metal Gear Solid', 'World of Warcraft', 'The Legend of Zelda']\n"
     ]
    }
   ],
   "source": [
    "class RecommendationSystem: \n",
    "    def __init__(self, user_item_file: str):\n",
    "        self.user_item_file = user_item_file\n",
    "        self.user_items: dict[str, set[str]] = {}\n",
    "        self.user_ids: list[str] = []\n",
    "        self.hash_tables: dict[str, HashTable] = {}\n",
    "    \n",
    "    def load_data(self):\n",
    "        # Read csv file and populate user_items and user_ids\n",
    "        with open(self.user_item_file, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # skip header\n",
    "            for row in reader:\n",
    "                if len(row) < 2:\n",
    "                    continue\n",
    "                user, item = row[0], row[1]\n",
    "                if user not in self.user_items:\n",
    "                    self.user_items[user] = set()\n",
    "                self.user_items[user].add(item)\n",
    "\n",
    "        self.user_ids = list(self.user_items.keys())\n",
    "\n",
    "    def build_recommendation_system(self, technique: str) -> HashTable:\n",
    "        # Build hash table based on specified technique\n",
    "        num_users = len(self.user_ids)\n",
    "        # make table size 2x number of users for lower load factor\n",
    "        table_size = max(11, 2 * num_users)\n",
    "        hash_table = HashTable(size=table_size, collision_avoidance=technique)\n",
    "\n",
    "        for user, items in self.user_items.items():\n",
    "            for item in items:\n",
    "                hash_table.insert(user, item)\n",
    "\n",
    "        self.hash_tables[technique] = hash_table\n",
    "        return hash_table\n",
    "    \n",
    "    def recommend_items(self, target_user: str, technique: str, top_n: int = 5) -> list[str]:\n",
    "        # For a given target_user and collision tecnhique: \n",
    "        # - Compute Jaccard similartiy to all other users \n",
    "        # - Convert user similartiy into item scores \n",
    "        # - Push items into MaxHeap by score\n",
    "        # - Return top n recommended items \n",
    "\n",
    "        if target_user not in self.user_items:\n",
    "            print(f\"User '{target_user}' not found in data.\")\n",
    "            return None\n",
    "        \n",
    "        target_items = self.user_items[target_user]\n",
    "        if not target_items:\n",
    "            return []\n",
    "        \n",
    "        # Computer user to user Jaccard similarity\n",
    "        similarity_by_user: dict[str, float] = {}\n",
    "\n",
    "        # O(n) where n is number of users\n",
    "        for other_user in self.user_ids:\n",
    "            if other_user == target_user: \n",
    "                continue\n",
    "            other_items = self.user_items[other_user]\n",
    "            if not other_items: \n",
    "                continue\n",
    "            \n",
    "            intersection_size = len(target_items & other_items)\n",
    "            union_size = len(target_items | other_items)\n",
    "\n",
    "            if union_size == 0:\n",
    "                continue\n",
    "\n",
    "            sim = intersection_size / union_size\n",
    "\n",
    "            if sim > 0:\n",
    "                similarity_by_user[other_user] = sim\n",
    "\n",
    "        # Convert user similarity into item scores\n",
    "        # You are looping through users and then all of the user's items so 0(n^2)\n",
    "        item_scores: dict[str, float] = {}\n",
    "        for other_user, sim in similarity_by_user.items():\n",
    "            other_items = self.user_items[other_user]\n",
    "            for item in other_items:\n",
    "                if item in target_items:\n",
    "                    continue\n",
    "                if item not in item_scores:\n",
    "                    item_scores[item] = 0.0\n",
    "                item_scores[item] += sim\n",
    "        \n",
    "        if not item_scores:\n",
    "            return []\n",
    "        \n",
    "        # Push items into MaxHeap by score\n",
    "        heap = MaxHeap()\n",
    "        for item, score in item_scores.items():\n",
    "            heap.push(score, item)\n",
    "            \n",
    "        # Return top_n recommended items\n",
    "        top = heap.top_n(top_n)\n",
    "        # top it a list of (score, item) --> we only want items\n",
    "        return [item for score, item in top]\n",
    "    \n",
    "rs = RecommendationSystem(\"user_item_data.csv\")\n",
    "rs.load_data()\n",
    "\n",
    "print(\"Number of users:\", len(rs.user_ids))\n",
    "print(\"First few users:\", rs.user_ids[:5])\n",
    "\n",
    "# Build hash table with separate chaining\n",
    "ht_sc = rs.build_recommendation_system(\"separate_chaining\")\n",
    "print(\"HashTable size (SC):\", ht_sc.size)\n",
    "print(\"SC collisions:\", ht_sc.collisions)\n",
    "\n",
    "example_user = rs.user_ids[0]\n",
    "print(\"Example user:\", example_user)\n",
    "print(\"Items for example user:\", rs.user_items[example_user])\n",
    "\n",
    "recs_sc = rs.recommend_items(example_user, \"separate_chaining\", top_n=5)\n",
    "print(\"Recommendations for\", example_user, \"(SC):\", recs_sc)\n",
    "\n",
    "ht_dh = rs.build_recommendation_system(\"double_hashing\")\n",
    "print(\"HashTable size (DH):\", ht_dh.size)\n",
    "print(\"DH collisions:\", ht_dh.collisions)\n",
    "\n",
    "recs_dh = rs.recommend_items(example_user, \"double_hashing\", top_n=5)\n",
    "print(\"Recommendations for\", example_user, \"(DH):\", recs_dh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae5246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Using collision avoidance technique: separate_chaining\n",
      "\n",
      "Recommendations for user6: ['Red Dead Redemption 2', 'Dragon Age', 'Metal Gear Solid', 'World of Warcraft', 'The Legend of Zelda']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000108 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Recommendations for user4: ['Silent Hill', 'Half-Life', 'Splatoon', 'Dota 2', 'Battlefield']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000068 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Recommendations for user1: ['Battlefield', 'The Last of Us', 'Gears of War', 'Splatoon', 'Bloodborne']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000054 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Recommendations for user5: ['Bayonetta', 'Resident Evil', 'Half-Life', 'Fire Emblem', 'Portal']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000059 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Recommendations for user2: ['Bayonetta', 'Splatoon', 'Bloodborne', 'Gears of War', 'Cyberpunk 2077']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000053 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Recommendations for user7: ['Bioshock', 'Super Mario Bros', 'Animal Crossing', 'The Legend of Zelda', 'League of Legends']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000055 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Recommendations for user3: ['League of Legends', 'Resident Evil', 'Bayonetta', 'Bioshock', 'Sekiro']\n",
      "Insertion Time: 0.000044 seconds\n",
      "Retrieval Time: 0.000049 seconds\n",
      "Collisions: 1\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Using collision avoidance technique: double_hashing\n",
      "\n",
      "Recommendations for user6: ['Red Dead Redemption 2', 'Dragon Age', 'Metal Gear Solid', 'World of Warcraft', 'The Legend of Zelda']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000057 seconds\n",
      "Collisions: 10\n",
      "\n",
      "Recommendations for user4: ['Silent Hill', 'Half-Life', 'Splatoon', 'Dota 2', 'Battlefield']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000057 seconds\n",
      "Collisions: 10\n",
      "\n",
      "Recommendations for user1: ['Battlefield', 'The Last of Us', 'Gears of War', 'Splatoon', 'Bloodborne']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000046 seconds\n",
      "Collisions: 10\n",
      "\n",
      "Recommendations for user5: ['Bayonetta', 'Resident Evil', 'Half-Life', 'Fire Emblem', 'Portal']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000055 seconds\n",
      "Collisions: 10\n",
      "\n",
      "Recommendations for user2: ['Bayonetta', 'Splatoon', 'Bloodborne', 'Gears of War', 'Cyberpunk 2077']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000045 seconds\n",
      "Collisions: 10\n",
      "\n",
      "Recommendations for user7: ['Bioshock', 'Super Mario Bros', 'Animal Crossing', 'The Legend of Zelda', 'League of Legends']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000052 seconds\n",
      "Collisions: 10\n",
      "\n",
      "Recommendations for user3: ['League of Legends', 'Resident Evil', 'Bayonetta', 'Bioshock', 'Sekiro']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000043 seconds\n",
      "Collisions: 10\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    rs = RecommendationSystem(\"user_item_data.csv\")\n",
    "    rs.load_data()\n",
    "\n",
    "    techniques = [\"separate_chaining\", \"double_hashing\"]\n",
    "\n",
    "    for tech in techniques:\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Using collision avoidance technique: {tech}\\n\")\n",
    "\n",
    "        # Build HashTable and time it\n",
    "        start_insert = time.time()\n",
    "        ht = rs.build_recommendation_system(tech)\n",
    "        end_insert = time.time()\n",
    "\n",
    "        insertion_time = end_insert - start_insert\n",
    "        collisions = ht.collisions\n",
    "\n",
    "       # Recommend items for each user and time it\n",
    "        for user in rs.user_ids:\n",
    "            start_retrieve = time.time()\n",
    "            recs = rs.recommend_items(user, tech, top_n=5)\n",
    "            end_retrieve = time.time()\n",
    "            retrieve_time = end_retrieve - start_retrieve\n",
    "\n",
    "            print(f\"Recommendations for {user}: {recs}\")\n",
    "            print(f\"Insertion Time: {insertion_time:.6f} seconds\")\n",
    "            print(f\"Retrieval Time: {retrieve_time:.6f} seconds\")\n",
    "            print(f\"Collisions: {collisions}\\n\")\n",
    "\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run main\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3d321",
   "metadata": {},
   "source": [
    "## Collision Technique Analysis \n",
    "\n",
    "In my experiment **separate chaining clearly had fewer collisions than double hashing**:\n",
    "- Separate Chaining Collisions: **1**\n",
    "- Double Hashing Collisions: **10**\n",
    "\n",
    "This result makes sense for this data set and table size. Each bucket can hold multiple keys in a small list. As soon as there's a collision we don't need to search for a new index, we just append to the list. Also the number of users is relatively small and the table is large so the overall number of collisions stays low. \n",
    "\n",
    "With double hashing every time two keys hash to the same initial index the algorithm has to jump around the table using the secondary hash function until it finds an empty spot and each of these jumps counts as a collision. These probes add up quickly. \n",
    "\n",
    "## Was MaxHeap a good choice? \n",
    "\n",
    "Using a MaxHeap for recommendations is reasonable in this project. It allows you to take the top five values numerically without having to sort the list every time. \n",
    "\n",
    "In this small of a data set it would have worked to just sort the `item_scores` dictionary and take the first N items, which would also work. However the MaxHeap implementation will scale much better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
